{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Colectiva viz\n",
        "Este notebook tiene código para generar visualizaciones de un conjunto de archivos con lecturas de EEG."
      ],
      "metadata": {
        "id": "veTrKUiFIQJ7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BDXTdFqMz8Y"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install mne"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/curiositry/EEGrunt/blob/master/data/eegrunt-obci-ovibe-test-data.csv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import mne\n",
        "\n",
        "# esto lee una grabacion que hice de muestra, pensé que eran 5min pero creo que es menos\n",
        "# df_fnames = [\n",
        "#        \"/content/alew_EEG_2022-04-28_200016.csv\",\n",
        "#        \"/content/amigamile_EEG_2022-04-29_190300.csv\",\n",
        "#        \"/content/erik_EEG_2022-04-30_185308.csv\",\n",
        "#        \"/content/fer_EEG_2022-04-29_183739.csv\",\n",
        "#        \"/content/guiada1_EEG_2022-04-28_194425.csv\",\n",
        "#        \"/content/quetzalli_EEG_2022-04-30_134611.csv\",\n",
        "# ]\n",
        "\n",
        "df_fnames = [\n",
        "       \"/content/alf_audio_EEG_2022-04-20_155442.csv\",\n",
        "       \"/content/emme_audio_EEG_2022-04-28_145148.csv\",\n",
        "       \"/content/feli_audio_EEG_2022-04-28_174706.csv\",\n",
        "       \"/content/les_audio_EEG_2022-04-20_153820.csv\",\n",
        "]\n",
        "\n",
        "dfs = []\n",
        "for fname in df_fnames:\n",
        "  df = pd.read_csv(fname, header=0, index_col = False)\n",
        "  dfs.append(df)"
      ],
      "metadata": {
        "id": "iPo05NIFNGQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for df in dfs:\n",
        "  print(len(df))"
      ],
      "metadata": {
        "id": "IiQTLy4LQPUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(4, 1, figsize=(30,30))\n",
        "for i, ax in enumerate(fig.axes):\n",
        "    ax.plot(dfs[i].iloc[-38811:,1:])\n",
        "    # ax.plot(data_fft[i][1:])\n",
        "    ax.title.set_text(df_fnames[i].split('/')[2].split('_')[0])\n",
        "    ax.set_xlabel('Time')\n",
        "    ax.set_ylabel('Amplitude')\n",
        "\n",
        "    #ax.set_xticks([])\n",
        "    #ax.set_yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gvpYTPY8PA1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_fft(all_channel_data):\n",
        "    data_fft = list(map(lambda x: np.fft.fft(x),all_channel_data))\n",
        "    return data_fft\n",
        "    \n",
        "def get_frequency(all_channel_data): \n",
        "    L = len(all_channel_data[0])\n",
        "    Fs = 64\n",
        "\n",
        "    #data_fft =  map(lambda x: np.fft.fft(x), all_channel_data)\n",
        "\n",
        "    data_fft = do_fft(all_channel_data)\n",
        "\n",
        "    #Compute frequency\n",
        "    freq1 = list(map(lambda x: abs((x/L)),data_fft))\n",
        "    frequency = list(map(lambda x: x[:int((L/2+1))] * 2, freq1))\n",
        "    \n",
        "    #List frequency\n",
        "    delta = list(map(lambda x: x[int(L*1//Fs-1):int(L*4/Fs)],frequency))\n",
        "    #abc = map(lambda x: int(x), list(delta))\n",
        "    #print(\"> \" + str(abc))\n",
        "    theta = list(map(lambda x: x[int(L*4//Fs-1):int(L*8//Fs)],frequency))\n",
        "    alpha = list(map(lambda x: x[int(L*5//Fs-1):int(L*13//Fs)],frequency))\n",
        "    beta = list(map(lambda x: x[int(L*13//Fs-1):int(L*30//Fs)],frequency))\n",
        "    gamma = list(map(lambda x: x[int(L*30//Fs-1):int(L*50//Fs)],frequency))\n",
        "   \n",
        "    # import pdb;pdb.set_trace()\n",
        "    return delta,theta,alpha,beta,gamma\n",
        "\n",
        "def get_feature(all_channel_data): \n",
        "\t\t\"\"\"\n",
        "\t\tGet feature from each frequency.\n",
        "\t\tInput: Channel data with dimension N x M. N denotes number of channel and M denotes number of EEG data from each channel.\n",
        "\t\tOutput: Feature (standard deviasion and mean) from all frequency bands and channels with dimesion 1 x M (number of feature).\n",
        "\t\t\"\"\"\n",
        "\t\t#Get frequency data\n",
        "\t\t(delta,theta,alpha,beta,gamma) = get_frequency(all_channel_data)\n",
        "\n",
        "\t\t#Compute feature std\n",
        "\t\tdelta_std = np.std(delta, axis=1)\n",
        "\t\ttheta_std = np.std(theta, axis=1)\n",
        "\t\talpha_std = np.std(alpha, axis=1)\n",
        "\t\tbeta_std = np.std(beta, axis=1)\n",
        "\t\tgamma_std = np.std(gamma, axis=1)\n",
        "\n",
        "\t\t#Compute feature mean\n",
        "\t\tdelta_m = np.mean(delta, axis=1)\n",
        "\t\ttheta_m = np.mean(theta, axis=1)\n",
        "\t\talpha_m = np.mean(alpha, axis=1)\n",
        "\t\tbeta_m = np.mean(beta, axis=1)\n",
        "\t\tgamma_m = np.mean(gamma, axis=1)\n",
        "\n",
        "\t\t#Concate feature\n",
        "\t\t# feature = np.array([delta_std,delta_m,theta_std,theta_m,alpha_std,alpha_m,beta_std,beta_m,gamma_std,gamma_m])\n",
        "\t\tfeature = np.array([delta_m,theta_m,alpha_m,beta_m,gamma_m])\n",
        "\t\t# feature = feature.T\n",
        "\t\tfeature = feature.ravel()\n",
        "  \n",
        "\t\treturn feature\n",
        "\n",
        "def compute_rolling_features(df_, size = 64):\n",
        "    rolling_feat = {'delta_m':[],\n",
        "                    'theta_m':[],\n",
        "                    'alpha_m':[],\n",
        "                    'beta_m':[],\n",
        "                    'gamma_m':[]}\n",
        "\n",
        "    for i in range(size, len(df_)+1):\n",
        "        feat = get_feature(np.asarray(df.T.iloc[:,i-size:i]))\n",
        "        rolling_feat['delta_m'].append(feat[0:5])\n",
        "        rolling_feat['theta_m'].append(feat[5:10])\n",
        "        rolling_feat['alpha_m'].append(feat[10:15])\n",
        "        rolling_feat['beta_m'].append(feat[15:20])\n",
        "        rolling_feat['gamma_m'].append(feat[20:25])\n",
        "\n",
        "    return rolling_feat\n"
      ],
      "metadata": {
        "id": "rtrxmBRVQfJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "viAHtux8YrzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rolling_waves_mu = []\n",
        "\n",
        "waves = ['delta_m', 'theta_m', 'alpha_m', 'beta_m', 'gamma_m']\n",
        "fig, axs = plt.subplots(len(dfs), 1, figsize=(30,30))\n",
        "for i, ax in enumerate(fig.axes):\n",
        "    test = compute_rolling_features(dfs[i])\n",
        "    ax.plot(test)\n",
        "    ax.title.set_text(df_fnames[i].split('/')[2].split('_')[0])\n",
        "    # ax.legend()\n",
        "\n",
        "\n",
        "    #ax.set_xticks([])\n",
        "    #ax.set_yticks([])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WlfLaa7ZXv77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MMuYlZmzYR79"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}